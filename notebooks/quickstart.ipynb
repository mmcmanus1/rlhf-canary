{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# RLHF Canary - Quickstart\n\nThis notebook demonstrates how to use RLHF Canary to detect regressions in your RLHF/finetuning pipelines.\n\n**What you'll learn:**\n1. Run a DPO canary training job\n2. Save metrics as a baseline\n3. Compare new runs against baseline\n4. Interpret regression reports\n5. Use custom thresholds\n6. Understand root cause analysis\n\n**Requirements:** GPU runtime (Runtime > Change runtime type > T4 GPU)",
   "metadata": {
    "id": "intro"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup"
   ],
   "metadata": {
    "id": "setup-header"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets accelerate trl peft bitsandbytes\n",
    "!pip install -q pydantic click PyYAML\n",
    "\n",
    "# Clone the repo\n",
    "!git clone https://github.com/mmcmanus1/rlhf-canary.git\n",
    "%cd rlhf-canary"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Verify installation and paths\nfrom pathlib import Path\n\nprint(\"=== Installation Verification ===\\n\")\n\n# Check 1: Working directory\ncwd = Path.cwd()\nprint(f\"Working directory: {cwd}\")\n\n# Check 2: Config files accessible\nconfig_path = cwd / \"configs\" / \"dpo_smoke.yaml\"\nif config_path.exists():\n    print(f\"Config file: {config_path}\")\nelse:\n    print(f\"ERROR: Config not found at {config_path}\")\n    print(\"Fix: Run '%cd rlhf-canary' or verify git clone succeeded\")\n    raise FileNotFoundError(f\"Config missing: {config_path}\")\n\n# Check 3: Canary module location\ntry:\n    import canary\n    canary_path = Path(canary.__file__).parent\n    print(f\"Canary module: {canary_path}\")\n\n    # Detect nested directory issue\n    if \"rlhf-canary/rlhf-canary\" in str(canary_path):\n        print(\"\\nWARNING: Nested directory detected!\")\n        print(\"Python is importing from a nested path.\")\n        print(\"Fix: Run these commands:\")\n        print(\"  !pip uninstall rlhf-canary -y\")\n        print(\"  %cd /content/rlhf-canary\")\n        print(\"  !pip install -e .\")\nexcept ImportError as e:\n    print(f\"ERROR: Cannot import canary: {e}\")\n    print(\"Fix: Restart runtime and re-run installation cells\")\n    raise\n\n# Check 4: TRL version compatibility\ntry:\n    import trl\n    trl_version = trl.__version__\n    print(f\"TRL version: {trl_version}\")\n\n    major, minor = map(int, trl_version.split(\".\")[:2])\n    if major == 0 and minor < 12:\n        print(f\"\\nWARNING: TRL {trl_version} detected. Version 0.12+ recommended.\")\n        print(\"Some features may not work correctly.\")\nexcept Exception as e:\n    print(f\"TRL check failed: {e}\")\n\nprint(\"\\n=== Verification Complete ===\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify GPU is available\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ],
   "metadata": {
    "id": "check-gpu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Show environment fingerprint\n",
    "!python -m canary.cli env"
   ],
   "metadata": {
    "id": "env-fingerprint"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Run Baseline Canary"
   ],
   "metadata": {
    "id": "baseline-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Run DPO smoke test (takes ~5-10 min on T4)\n",
    "!python -m canary.cli run configs/dpo_smoke.yaml -o ./canary_output"
   ],
   "metadata": {
    "id": "run-baseline"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Find and display the metrics\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "metrics_files = list(Path('./canary_output').rglob('metrics.json'))\n",
    "if metrics_files:\n",
    "    baseline_path = metrics_files[0]\n",
    "    print(f\"Baseline metrics: {baseline_path}\")\n",
    "    \n",
    "    with open(baseline_path) as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(f\"\\nRun ID: {metrics['run_id']}\")\n",
    "    print(f\"Duration: {metrics['duration_seconds']:.1f}s\")\n",
    "    print(f\"Step time (mean): {metrics['perf']['step_time']['mean']:.4f}s\")\n",
    "    print(f\"Tokens/sec: {metrics['perf']['approx_tokens_per_sec']:.0f}\")\n",
    "    print(f\"Peak memory: {metrics['perf']['max_mem_mb']:.0f}MB\")\n",
    "    print(f\"NaN steps: {metrics['stability']['nan_steps']}\")"
   ],
   "metadata": {
    "id": "show-baseline"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save as baseline\n",
    "!mkdir -p baselines\n",
    "!cp {baseline_path} baselines/dpo_baseline.json\n",
    "print(\"Baseline saved to baselines/dpo_baseline.json\")"
   ],
   "metadata": {
    "id": "save-baseline"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Run Again and Compare\n",
    "\n",
    "Now let's run another canary and compare it to our baseline."
   ],
   "metadata": {
    "id": "compare-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Run another canary\n",
    "!python -m canary.cli run configs/dpo_smoke.yaml -o ./canary_output"
   ],
   "metadata": {
    "id": "run-current"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Find the new metrics file\nmetrics_files = sorted(Path('./canary_output').rglob('metrics.json'), key=lambda p: p.stat().st_mtime)\nif not metrics_files:\n    raise FileNotFoundError(\"No metrics files found. Run cells 6 and 10 first to generate canary runs.\")\ncurrent_path = metrics_files[-1]  # Most recent\nprint(f\"Current metrics: {current_path}\")",
   "metadata": {
    "id": "find-current"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compare to baseline\n",
    "!python -m canary.cli compare {current_path} baselines/dpo_baseline.json --threshold-tier smoke"
   ],
   "metadata": {
    "id": "compare"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Simulate a Regression\n",
    "\n",
    "Let's intentionally create a slower config to see regression detection in action."
   ],
   "metadata": {
    "id": "regression-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a \"slower\" config (smaller batch = more steps = slower)\n",
    "slow_config = \"\"\"\n",
    "name: dpo_slow\n",
    "description: Intentionally slow config for regression demo\n",
    "\n",
    "model_name: EleutherAI/pythia-70m\n",
    "use_peft: true\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "\n",
    "training_type: dpo\n",
    "max_steps: 100\n",
    "batch_size: 1  # Smaller batch = slower!\n",
    "gradient_accumulation_steps: 8\n",
    "learning_rate: 5.0e-5\n",
    "max_length: 256\n",
    "warmup_steps: 10\n",
    "\n",
    "beta: 0.1\n",
    "max_prompt_length: 64\n",
    "\n",
    "dataset_name: Anthropic/hh-rlhf\n",
    "dataset_split: train\n",
    "dataset_size: 512\n",
    "seed: 42\n",
    "\n",
    "output_dir: ./canary_output\n",
    "metrics_warmup_steps: 10\n",
    "\"\"\"\n",
    "\n",
    "with open('configs/dpo_slow.yaml', 'w') as f:\n",
    "    f.write(slow_config)\n",
    "\n",
    "print(\"Created slow config\")"
   ],
   "metadata": {
    "id": "create-slow-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run the slow config\n",
    "!python -m canary.cli run configs/dpo_slow.yaml -o ./canary_output"
   ],
   "metadata": {
    "id": "run-slow"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Compare slow run to baseline - should show regression!\nmetrics_files = sorted(Path('./canary_output').rglob('metrics.json'), key=lambda p: p.stat().st_mtime)\nif not metrics_files:\n    raise FileNotFoundError(\"No metrics files found. Run cells 6, 10, and 15 first.\")\nslow_path = metrics_files[-1]\n\n!python -m canary.cli compare {slow_path} baselines/dpo_baseline.json --threshold-tier smoke",
   "metadata": {
    "id": "compare-slow"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Custom Thresholds\n\nYou can customize regression thresholds using YAML files or inline in your config.",
   "metadata": {
    "id": "next-steps"
   }
  },
  {
   "cell_type": "code",
   "source": "# Create a custom threshold file\ncustom_thresholds = \"\"\"\n# Custom thresholds - start from smoke tier but customize\nbase_tier: smoke\n\n# Override specific thresholds\nmax_step_time_increase_pct: 20.0  # Allow 20% step time increase\nmax_tps_drop_pct: 15.0            # Allow 15% throughput drop\nmax_mem_increase_mb: 750.0        # Allow 750MB memory increase\n\"\"\"\n\nwith open('custom_thresholds.yaml', 'w') as f:\n    f.write(custom_thresholds)\n\nprint(\"Created custom_thresholds.yaml\")\nprint(\"\\nAvailable threshold tiers:\")\nprint(\"  - smoke: Lenient (15% step time, 12% TPS, 1000MB memory)\")\nprint(\"  - default: Balanced (10% step time, 8% TPS, 500MB memory)\")\nprint(\"  - perf: Strict (8% step time, 5% TPS, 300MB memory)\")\nprint(\"  - nightly: Strictest (5% step time, 3% TPS, 200MB memory)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Compare using custom thresholds\n# The slow run might pass with more lenient thresholds!\n!python -m canary.cli compare {slow_path} baselines/dpo_baseline.json --threshold-file custom_thresholds.yaml",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Root Cause Analysis\n\nWhen regressions are detected, the canary provides heuristic-based analysis to help identify the root cause. The system analyzes:\n\n- **Gradient norms**: Detects gradient explosion and training instability\n- **GPU utilization**: Identifies CPU bottlenecks (low GPU util = waiting on data)\n- **Dataloader wait time**: Pinpoints data loading bottlenecks\n- **Memory patterns**: Distinguishes memory leaks from fragmentation\n- **Combined patterns**: Cross-check analysis (e.g., step time + memory = fragmentation)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Programmatically access root cause analysis\nfrom canary.compare.stats import compare_to_baseline, load_metrics\nfrom canary.compare.thresholds import SMOKE_THRESHOLDS\nfrom canary.compare.heuristics import analyze_regression, format_suspects_markdown\n\n# Load metrics\ncurrent = load_metrics(str(slow_path))\nbaseline = load_metrics('baselines/dpo_baseline.json')\n\n# Run comparison\nreport = compare_to_baseline(current, baseline, SMOKE_THRESHOLDS)\n\n# Get root cause analysis\nif not report.passed:\n    analysis = analyze_regression(report, current, baseline)\n    print(\"Root Cause Analysis\")\n    print(\"=\" * 50)\n    print(f\"\\nSummary: {analysis.summary}\")\n    print(f\"\\nTop suspects ({len(analysis.suspects)} found):\")\n    for i, suspect in enumerate(analysis.suspects[:3], 1):\n        print(f\"\\n  #{i} {suspect.category.value.title()} (confidence: {suspect.confidence:.0%})\")\n        print(f\"      {suspect.description}\")\n        for ev in suspect.evidence:\n            print(f\"      - {ev}\")\nelse:\n    print(\"No regressions detected!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. GitHub Integration\n\nRLHF Canary includes built-in GitHub integration for CI/CD workflows.\n\n### Available Commands\n\n```bash\n# Post comparison results to a PR (comment + commit status)\ncanary gh-report <current> <baseline> --threshold-tier smoke\n\n# Options:\n#   --post-comment/--no-comment   Post PR comment (default: yes)\n#   --update-status/--no-status   Update commit status (default: yes)\n#   --threshold-file PATH         Use custom thresholds\n```\n\n### Workflow Files\n\nTwo workflow files are included:\n- `workflows/pr_canary.yml` - Runs on every PR (smoke tests)\n- `workflows/nightly_canary.yml` - Runs daily at 2 AM UTC (soak tests)\n\n### Test Configurations\n\n| Config | Steps | Duration | Use Case |\n|--------|-------|----------|----------|\n| `dpo_smoke.yaml` | 100 | ~5-10 min | PR gating |\n| `dpo_perf.yaml` | 500 | ~20-45 min | Performance analysis |\n| `dpo_nightly.yaml` | 2000 | ~1-2 hr | Nightly soak tests |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Next Steps\n\nNow that you've learned the basics, here are some ways to integrate RLHF Canary into your workflow:\n\n### For Your Repository\n\n1. **Copy workflow files** to `.github/workflows/`:\n   - `pr_canary.yml` for PR gating\n   - `nightly_canary.yml` for nightly soak tests\n\n2. **Create a baseline** from your current main branch:\n   ```bash\n   canary run configs/dpo_smoke.yaml\n   canary save-baseline ./canary_output/*/metrics.json ./baselines/main.json\n   ```\n\n3. **Customize thresholds** for your use case in a `custom_thresholds.yaml` file\n\n### CLI Reference\n\n```bash\ncanary --help                    # Show all commands\ncanary env                       # Show environment fingerprint\ncanary run <config>              # Run a canary job\ncanary compare <cur> <base>      # Compare metrics to baseline\ncanary gh-report <cur> <base>    # Post results to GitHub PR\ncanary save-baseline <src> <dst> # Save metrics as baseline\ncanary init-config <path>        # Generate sample config\n```\n\n### Learn More\n\nSee the [README](https://github.com/mmcmanus1/rlhf-canary) for complete documentation.",
   "metadata": {}
  }
 ]
}