{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mmcmanus1/rlhf-canary/blob/main/notebooks/01_quickstart.ipynb)\n\n# RLHF Canary - Quickstart\n\nGet started with RLHF Canary in minutes. Learn the core workflow for detecting regressions in your RLHF/finetuning pipelines before they reach production.\n\n**What you'll learn:**\n1. Run a DPO canary training job\n2. Save metrics as a baseline\n3. Compare new runs against baseline\n4. Interpret regression reports\n5. Use custom thresholds\n6. Understand root cause analysis\n\n**Requirements:** GPU runtime (Runtime > Change runtime type > T4 GPU)",
   "metadata": {
    "id": "intro"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup"
   ],
   "metadata": {
    "id": "setup-header"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": "import os\nimport re\nimport sys\n\nprint(\"Starting Environment Setup...\")\n\n# --- 1. Clone or update the repo ---\nif not os.path.exists(\"/content/rlhf-canary\"):\n    !git clone https://github.com/mmcmanus1/rlhf-canary.git /content/rlhf-canary\nelse:\n    !cd /content/rlhf-canary && git pull --ff-only\n\n%cd /content/rlhf-canary\n\n# --- 2. Force-Install the \"Safe Harbor\" Stack ---\n# These specific versions avoid the TRL 0.12+ dtype bug and Transformers 4.46+ generator bug\n# We use --no-deps to prevent pip from trying to be \"smart\" and upgrading things\n!pip install \"trl==0.11.4\" \"transformers==4.44.2\" \"peft==0.12.0\" \"accelerate==0.34.2\" \"tokenizers==0.19.1\" --force-reinstall --no-deps --quiet\n!pip install -q datasets pydantic click PyYAML bitsandbytes\nprint(\"Libraries installed (TRL 0.11.4 / Transformers 4.44.2)\")\n\n# --- 3. Patch pyproject.toml (Prevent future drift) ---\nproject_file = \"/content/rlhf-canary/pyproject.toml\"\nif os.path.exists(project_file):\n    with open(project_file, \"r\") as f:\n        content = f.read()\n    \n    # Ensure TRL is pinned to 0.11.4 in the config file\n    if \"trl==0.11.4\" not in content:\n        content = re.sub(r'trl[<>=!~]+[\\d\\.]+', 'trl==0.11.4', content)\n        with open(project_file, \"w\") as f:\n            f.write(content)\n        print(\"Config file patched to lock TRL 0.11.4\")\n\n# --- 4. Patch Source Code (Compatibility Fix) ---\n# TRL 0.11.4 uses 'tokenizer=' argument. Newer code uses 'processing_class='.\n# We auto-detect and revert this change if found.\nrunner_file = \"/content/rlhf-canary/canary/runner/local.py\"\nif os.path.exists(runner_file):\n    with open(runner_file, \"r\") as f:\n        code = f.read()\n    \n    if \"processing_class=\" in code:\n        code = code.replace(\"processing_class=\", \"tokenizer=\")\n        with open(runner_file, \"w\") as f:\n            f.write(code)\n        print(\"Code patched: Reverted 'processing_class' to 'tokenizer'\")\n    else:\n        print(\"Code is already compatible.\")\n\n# --- 5. Install the package ---\n!pip install -e . --quiet\n\nprint(\"Environment Ready! You can run your training now.\")"
  },
  {
   "cell_type": "code",
   "source": "# Verify installation and paths\nfrom pathlib import Path\n\nprint(\"=== Installation Verification ===\\n\")\n\n# Check 1: Working directory\ncwd = Path.cwd()\nprint(f\"Working directory: {cwd}\")\n\n# Check 2: Config files accessible\nconfig_path = cwd / \"configs\" / \"dpo_smoke.yaml\"\nif config_path.exists():\n    print(f\"Config file: {config_path}\")\nelse:\n    print(f\"ERROR: Config not found at {config_path}\")\n    print(\"Fix: Run '%cd rlhf-canary' or verify git clone succeeded\")\n    raise FileNotFoundError(f\"Config missing: {config_path}\")\n\n# Check 3: Canary module location\ntry:\n    import canary\n    canary_path = Path(canary.__file__).parent\n    print(f\"Canary module: {canary_path}\")\n\n    # Detect nested directory issue\n    if \"rlhf-canary/rlhf-canary\" in str(canary_path):\n        print(\"\\nWARNING: Nested directory detected!\")\n        print(\"Python is importing from a nested path.\")\n        print(\"Fix: Run these commands:\")\n        print(\"  !pip uninstall rlhf-canary -y\")\n        print(\"  %cd /content/rlhf-canary\")\n        print(\"  !pip install -e .\")\nexcept ImportError as e:\n    print(f\"ERROR: Cannot import canary: {e}\")\n    print(\"Fix: Restart runtime and re-run installation cells\")\n    raise\n\n# Check 4: TRL version compatibility\ntry:\n    import trl\n    trl_version = trl.__version__\n    print(f\"TRL version: {trl_version}\")\n\n    major, minor, *_ = trl_version.split(\".\")\n    major, minor = int(major), int(minor)\n    if major == 0 and minor >= 12:\n        print(f\"\\nWARNING: TRL {trl_version} detected. This version has dtype bugs.\")\n        print(\"Run the setup cell again to install TRL 0.11.4\")\n    elif major == 0 and minor == 11:\n        print(\"TRL version OK (0.11.x)\")\nexcept Exception as e:\n    print(f\"TRL check failed: {e}\")\n\n# Check 5: Transformers version\ntry:\n    import transformers\n    tf_version = transformers.__version__\n    print(f\"Transformers version: {tf_version}\")\n    \n    major, minor, *_ = tf_version.split(\".\")\n    major, minor = int(major), int(minor)\n    if major >= 4 and minor >= 46:\n        print(f\"\\nWARNING: Transformers {tf_version} detected. This version has compatibility issues with TRL 0.11.x\")\n        print(\"Run the setup cell again to install Transformers 4.44.2\")\n    else:\n        print(\"Transformers version OK\")\nexcept Exception as e:\n    print(f\"Transformers check failed: {e}\")\n\nprint(\"\\n=== Verification Complete ===\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify GPU is available\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ],
   "metadata": {
    "id": "check-gpu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Show environment fingerprint\n",
    "!python -m canary.cli env"
   ],
   "metadata": {
    "id": "env-fingerprint"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Run Baseline Canary"
   ],
   "metadata": {
    "id": "baseline-header"
   }
  },
  {
   "cell_type": "code",
   "source": "# Run DPO smoke test (takes ~5-10 min on T4)\n!python -m canary.cli run configs/dpo_smoke.yaml -o ./canary_output/baseline",
   "metadata": {
    "id": "run-baseline"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Find and display the metrics\nimport json\nfrom pathlib import Path\n\nbaseline_path = next(Path('./canary_output/baseline').rglob('metrics.json'))\nprint(f\"Baseline metrics: {baseline_path}\")\n\nwith open(baseline_path) as f:\n    metrics = json.load(f)\n\nprint(f\"\\nRun ID: {metrics['run_id']}\")\nprint(f\"Duration: {metrics['duration_seconds']:.1f}s\")\nprint(f\"Step time (mean): {metrics['perf']['step_time']['mean']:.4f}s\")\nprint(f\"Tokens/sec: {metrics['perf']['approx_tokens_per_sec']:.0f}\")\nprint(f\"Peak memory: {metrics['perf']['max_mem_mb']:.0f}MB\")\nprint(f\"NaN steps: {metrics['stability']['nan_steps']}\")",
   "metadata": {
    "id": "show-baseline"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save as baseline\n!mkdir -p baselines\n!cp {baseline_path} baselines/dpo_baseline.json\nprint(\"Baseline saved to baselines/dpo_baseline.json\")",
   "metadata": {
    "id": "save-baseline"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Run Again and Compare\n",
    "\n",
    "Now let's run another canary and compare it to our baseline."
   ],
   "metadata": {
    "id": "compare-header"
   }
  },
  {
   "cell_type": "code",
   "source": "# Run another canary\n!python -m canary.cli run configs/dpo_smoke.yaml -o ./canary_output/run2",
   "metadata": {
    "id": "run-current"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Find the new metrics file\ncurrent_path = next(Path('./canary_output/run2').rglob('metrics.json'))\nprint(f\"Current metrics: {current_path}\")",
   "metadata": {
    "id": "find-current"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compare to baseline\n",
    "!python -m canary.cli compare {current_path} baselines/dpo_baseline.json --threshold-tier smoke"
   ],
   "metadata": {
    "id": "compare"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Simulate a Regression\n",
    "\n",
    "Let's intentionally create a slower config to see regression detection in action."
   ],
   "metadata": {
    "id": "regression-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a \"slower\" config (smaller batch = more steps = slower)\n",
    "slow_config = \"\"\"\n",
    "name: dpo_slow\n",
    "description: Intentionally slow config for regression demo\n",
    "\n",
    "model_name: EleutherAI/pythia-70m\n",
    "use_peft: true\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "\n",
    "training_type: dpo\n",
    "max_steps: 100\n",
    "batch_size: 1  # Smaller batch = slower!\n",
    "gradient_accumulation_steps: 8\n",
    "learning_rate: 5.0e-5\n",
    "max_length: 256\n",
    "warmup_steps: 10\n",
    "\n",
    "beta: 0.1\n",
    "max_prompt_length: 64\n",
    "\n",
    "dataset_name: Anthropic/hh-rlhf\n",
    "dataset_split: train\n",
    "dataset_size: 512\n",
    "seed: 42\n",
    "\n",
    "output_dir: ./canary_output\n",
    "metrics_warmup_steps: 10\n",
    "\"\"\"\n",
    "\n",
    "with open('configs/dpo_slow.yaml', 'w') as f:\n",
    "    f.write(slow_config)\n",
    "\n",
    "print(\"Created slow config\")"
   ],
   "metadata": {
    "id": "create-slow-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Run the slow config\n!python -m canary.cli run configs/dpo_slow.yaml -o ./canary_output/slow_run",
   "metadata": {
    "id": "run-slow"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Compare slow run to baseline - should show regression!\nslow_path = next(Path('./canary_output/slow_run').rglob('metrics.json'))\nprint(f\"Comparing: {slow_path}\")\n\n!python -m canary.cli compare {slow_path} baselines/dpo_baseline.json --threshold-tier smoke",
   "metadata": {
    "id": "compare-slow"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Custom Thresholds\n\nYou can customize regression thresholds using YAML files or inline in your config.",
   "metadata": {
    "id": "next-steps"
   }
  },
  {
   "cell_type": "code",
   "source": "# Create a custom threshold file\ncustom_thresholds = \"\"\"\n# Custom thresholds - start from smoke tier but customize\nbase_tier: smoke\n\n# Override specific thresholds (lenient enough for the slow config demo)\nmax_step_time_increase_pct: 50.0  # Allow 50% step time increase\nmax_tps_drop_pct: 35.0            # Allow 35% throughput drop\nmax_mem_increase_mb: 750.0        # Allow 750MB memory increase\n\"\"\"\n\nwith open('custom_thresholds.yaml', 'w') as f:\n    f.write(custom_thresholds)\n\nprint(\"Created custom_thresholds.yaml\")\nprint(\"\\nAvailable threshold tiers:\")\nprint(\"  - smoke: Lenient (15% step time, 12% TPS, 1000MB memory)\")\nprint(\"  - default: Balanced (10% step time, 8% TPS, 500MB memory)\")\nprint(\"  - perf: Strict (8% step time, 5% TPS, 300MB memory)\")\nprint(\"  - nightly: Strictest (5% step time, 3% TPS, 200MB memory)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Compare using custom thresholds\n# With lenient thresholds, the slow run passes despite the performance difference\n!python -m canary.cli compare {slow_path} baselines/dpo_baseline.json --threshold-file custom_thresholds.yaml",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Root Cause Analysis\n\nWhen regressions are detected, the canary provides heuristic-based analysis to help identify the root cause. The system analyzes:\n\n- **Gradient norms**: Detects gradient explosion and training instability\n- **GPU utilization**: Identifies CPU bottlenecks (low GPU util = waiting on data)\n- **Dataloader wait time**: Pinpoints data loading bottlenecks\n- **Memory patterns**: Distinguishes memory leaks from fragmentation\n- **Combined patterns**: Cross-check analysis (e.g., step time + memory = fragmentation)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Programmatically access root cause analysis\nfrom canary.compare.stats import compare_to_baseline, load_metrics\nfrom canary.compare.thresholds import SMOKE_THRESHOLDS\nfrom canary.compare.heuristics import analyze_regression, format_suspects_markdown\n\n# Load metrics\ncurrent = load_metrics(str(slow_path))\nbaseline = load_metrics('baselines/dpo_baseline.json')\n\n# Run comparison\nreport = compare_to_baseline(current, baseline, SMOKE_THRESHOLDS)\n\n# Get root cause analysis\nif not report.passed:\n    analysis = analyze_regression(report, current, baseline)\n    print(\"Root Cause Analysis\")\n    print(\"=\" * 50)\n    print(f\"\\nSummary: {analysis.summary}\")\n    print(f\"\\nTop suspects ({len(analysis.suspects)} found):\")\n    for i, suspect in enumerate(analysis.suspects[:3], 1):\n        print(f\"\\n  #{i} {suspect.category.value.title()} (confidence: {suspect.confidence:.0%})\")\n        print(f\"      {suspect.description}\")\n        for ev in suspect.evidence:\n            print(f\"      - {ev}\")\nelse:\n    print(\"No regressions detected!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. GitHub Integration\n\nRLHF Canary includes built-in GitHub integration for CI/CD workflows.\n\n### Available Commands\n\n```bash\n# Post comparison results to a PR (comment + commit status)\ncanary gh-report <current> <baseline> --threshold-tier smoke\n\n# Options:\n#   --post-comment/--no-comment   Post PR comment (default: yes)\n#   --update-status/--no-status   Update commit status (default: yes)\n#   --threshold-file PATH         Use custom thresholds\n```\n\n### Workflow Files\n\nTwo workflow files are included:\n- `workflows/pr_canary.yml` - Runs on every PR (smoke tests)\n- `workflows/nightly_canary.yml` - Runs daily at 2 AM UTC (soak tests)\n\n### Test Configurations\n\n| Config | Steps | Duration | Use Case |\n|--------|-------|----------|----------|\n| `dpo_smoke.yaml` | 100 | ~5-10 min | PR gating |\n| `dpo_perf.yaml` | 500 | ~20-45 min | Performance analysis |\n| `dpo_nightly.yaml` | 2000 | ~1-2 hr | Nightly soak tests |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Next Steps\n\nNow that you've learned the basics, here are some ways to integrate RLHF Canary into your workflow:\n\n### For Your Repository\n\n1. **Copy workflow files** to `.github/workflows/`:\n   - `pr_canary.yml` for PR gating\n   - `nightly_canary.yml` for nightly soak tests\n\n2. **Create a baseline** from your current main branch:\n   ```bash\n   canary run configs/dpo_smoke.yaml\n   canary save-baseline ./canary_output/*/metrics.json ./baselines/main.json\n   ```\n\n3. **Customize thresholds** for your use case in a `custom_thresholds.yaml` file\n\n### CLI Reference\n\n```bash\ncanary --help                    # Show all commands\ncanary env                       # Show environment fingerprint\ncanary run <config>              # Run a canary job\ncanary compare <cur> <base>      # Compare metrics to baseline\ncanary gh-report <cur> <base>    # Post results to GitHub PR\ncanary save-baseline <src> <dst> # Save metrics as baseline\ncanary init-config <path>        # Generate sample config\n```\n\n### Learn More\n\nSee the [README](https://github.com/mmcmanus1/rlhf-canary) for complete documentation.",
   "metadata": {}
  }
 ]
}