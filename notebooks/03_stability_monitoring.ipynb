{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mmcmanus1/rlhf-canary/blob/main/notebooks/03_stability_monitoring.ipynb)\n\n# Stability Monitoring: Detecting Training Instabilities\n\nCatch NaN explosions, loss divergence, and gradient problems before they waste your training run. Learn to recognize early warning signs and predict failures before they happen.\n\n**What you'll learn:**\n1. What stability metrics are tracked (NaN/Inf, loss divergence, gradient norms)\n2. PPO-specific stability metrics (KL divergence, entropy, clip fraction)\n3. How to inject artificial instabilities for testing\n4. Interpreting stability regression reports\n5. Early warning patterns - predict run failure before it happens\n\n**Requirements:** GPU runtime (Runtime > Change runtime type > T4 GPU)\n\n**Runtime:** ~12-15 minutes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport re\nimport sys\n\nprint(\"Starting Environment Setup...\")\n\n# --- 1. Clone or update the repo ---\nif not os.path.exists(\"/content/rlhf-canary\"):\n    !git clone https://github.com/mmcmanus1/rlhf-canary.git /content/rlhf-canary\nelse:\n    !cd /content/rlhf-canary && git pull --ff-only\n\n%cd /content/rlhf-canary\n\n# --- 2. Force-Install the \"Safe Harbor\" Stack ---\n!pip install \"trl==0.11.4\" \"transformers==4.44.2\" \"peft==0.12.0\" \"accelerate==0.34.2\" \"tokenizers==0.19.1\" --force-reinstall --no-deps --quiet\n!pip install -q datasets pydantic click PyYAML bitsandbytes\nprint(\"Libraries installed (TRL 0.11.4 / Transformers 4.44.2)\")\n\n# --- 3. Patch pyproject.toml (Prevent future drift) ---\nproject_file = \"/content/rlhf-canary/pyproject.toml\"\nif os.path.exists(project_file):\n    with open(project_file, \"r\") as f:\n        content = f.read()\n    \n    if \"trl==0.11.4\" not in content:\n        content = re.sub(r'trl[<>=!~]+[\\d\\.]+', 'trl==0.11.4', content)\n        with open(project_file, \"w\") as f:\n            f.write(content)\n        print(\"Config file patched to lock TRL 0.11.4\")\n\n# --- 4. Patch Source Code (Compatibility Fix) ---\nrunner_file = \"/content/rlhf-canary/canary/runner/local.py\"\nif os.path.exists(runner_file):\n    with open(runner_file, \"r\") as f:\n        code = f.read()\n    \n    if \"processing_class=\" in code:\n        code = code.replace(\"processing_class=\", \"tokenizer=\")\n        with open(runner_file, \"w\") as f:\n            f.write(code)\n        print(\"Code patched: Reverted 'processing_class' to 'tokenizer'\")\n    else:\n        print(\"Code is already compatible.\")\n\n# --- 5. Install the package ---\n!pip install -e . --quiet\n\nprint(\"Environment Ready!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU and installation\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "import canary\n",
    "print(f\"Canary module loaded from: {canary.__file__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Stability Metrics\n",
    "\n",
    "RLHF Canary tracks several stability indicators:\n",
    "\n",
    "### Core Stability Metrics\n",
    "\n",
    "| Metric | What it detects | Failure threshold |\n",
    "|--------|-----------------|-------------------|\n",
    "| `nan_steps` | NaN in loss/gradients | Any NaN = fail |\n",
    "| `inf_steps` | Inf in loss/gradients | Any Inf = fail |\n",
    "| `loss_diverged` | Loss increasing over time | late_loss > early_loss * 1.5 |\n",
    "| `grad_norm_values` | Gradient explosion | Tracked for analysis |\n",
    "\n",
    "### PPO-Specific Metrics\n",
    "\n",
    "| Metric | What it indicates | Warning sign |\n",
    "|--------|-------------------|-------------|\n",
    "| `objective/kl` | Policy drift from reference | KL spike = instability |\n",
    "| `objective/entropy` | Exploration diversity | Entropy collapse = stuck |\n",
    "| `ppo/clipfrac` | Update clipping frequency | High clip = too aggressive |\n",
    "| `ppo/policy_loss` | Actor loss | NaN/Inf = fail |\n",
    "| `ppo/value_loss` | Critic loss | NaN/Inf = fail |\n",
    "\n",
    "### Stability Keys (only these trigger NaN/Inf detection)\n",
    "\n",
    "```python\n",
    "STABILITY_KEYS = {\n",
    "    \"loss\", \"train_loss\", \"policy_loss\", \"value_loss\",\n",
    "    \"grad_norm\", \"rewards/chosen\", \"rewards/rejected\", \"kl\",\n",
    "    # PPO-specific\n",
    "    \"objective/kl\", \"objective/entropy\", \"ppo/policy_loss\",\n",
    "    \"ppo/value_loss\", \"ppo/clipfrac\", \"ppo/mean_non_score_reward\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a Stable Baseline (DPO)\n",
    "\n",
    "First, let's run a stable training job to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a stable DPO canary\n",
    "!python -m canary.cli run configs/dpo_smoke.yaml -o ./stability_output/stable_dpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom pathlib import Path\n\n# Load and display stability metrics\nstable_paths = list(Path('./stability_output/stable_dpo').rglob('metrics.json'))\nif not stable_paths:\n    raise FileNotFoundError(\"No metrics.json found for stable DPO run. Did the training complete?\")\n\nstable_path = stable_paths[0]\nwith open(stable_path) as f:\n    stable_metrics = json.load(f)\n\nprint(\"=\"*60)\nprint(\"STABLE DPO RUN - STABILITY METRICS\")\nprint(\"=\"*60)\n\nstability = stable_metrics['stability']\nprint(f\"\\nNaN steps:      {stability['nan_steps']}\")\nprint(f\"Inf steps:      {stability['inf_steps']}\")\nprint(f\"Loss diverged:  {stability['loss_diverged']}\")\nprint(f\"Final loss:     {stability['final_loss']:.4f}\")\n\n# Show loss trajectory\nloss_values = stability['loss_values']\nif len(loss_values) > 10:\n    print(f\"\\nLoss trajectory (first 5): {[f'{v:.4f}' for v in loss_values[:5]]}\")\n    print(f\"Loss trajectory (last 5):  {[f'{v:.4f}' for v in loss_values[-5:]]}\")\n\nprint(\"\\nThis is a healthy run - no NaNs, no Infs, loss decreasing.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inject Instability: High Learning Rate\n",
    "\n",
    "A common cause of training instability is a learning rate that's too high. Let's create a config that will cause gradient explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an unstable config with high learning rate\n",
    "unstable_config = \"\"\"\n",
    "name: dpo_unstable_lr\n",
    "description: Intentionally unstable config - high learning rate\n",
    "\n",
    "# Model configuration\n",
    "model_name: EleutherAI/pythia-70m\n",
    "use_peft: true\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "\n",
    "# Training configuration - DANGEROUSLY HIGH LR\n",
    "training_type: dpo\n",
    "max_steps: 50\n",
    "batch_size: 2\n",
    "gradient_accumulation_steps: 4\n",
    "learning_rate: 1.0e-2   # 200x higher than normal!\n",
    "max_length: 256\n",
    "warmup_steps: 5\n",
    "\n",
    "# DPO-specific\n",
    "beta: 0.1\n",
    "max_prompt_length: 64\n",
    "\n",
    "# Dataset configuration\n",
    "dataset_name: Anthropic/hh-rlhf\n",
    "dataset_split: train\n",
    "dataset_size: 256\n",
    "seed: 42\n",
    "\n",
    "# Output configuration\n",
    "output_dir: ./stability_output\n",
    "metrics_warmup_steps: 5\n",
    "\n",
    "profiler:\n",
    "  enabled: false\n",
    "\"\"\"\n",
    "\n",
    "with open('configs/dpo_unstable_lr.yaml', 'w') as f:\n",
    "    f.write(unstable_config)\n",
    "\n",
    "print(\"Created unstable config with learning_rate=1.0e-2 (200x normal)\")\n",
    "print(\"This will likely cause gradient explosion or NaNs...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the unstable config\n",
    "!python -m canary.cli run configs/dpo_unstable_lr.yaml -o ./stability_output/unstable_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the stability metrics for the unstable run\n",
    "unstable_paths = list(Path('./stability_output/unstable_lr').rglob('metrics.json'))\n",
    "\n",
    "if unstable_paths:\n",
    "    with open(unstable_paths[0]) as f:\n",
    "        unstable_metrics = json.load(f)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"UNSTABLE RUN - STABILITY METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    stability = unstable_metrics['stability']\n",
    "    print(f\"\\nNaN steps:      {stability['nan_steps']} {'FAIL!' if stability['nan_steps'] > 0 else ''}\")\n",
    "    print(f\"Inf steps:      {stability['inf_steps']} {'FAIL!' if stability['inf_steps'] > 0 else ''}\")\n",
    "    print(f\"Loss diverged:  {stability['loss_diverged']} {'WARNING!' if stability['loss_diverged'] else ''}\")\n",
    "    print(f\"Final loss:     {stability['final_loss']}\")\n",
    "    \n",
    "    # Show loss trajectory\n",
    "    loss_values = stability['loss_values']\n",
    "    if len(loss_values) > 10:\n",
    "        print(f\"\\nLoss trajectory (first 5): {[f'{v:.4f}' for v in loss_values[:5]]}\")\n",
    "        print(f\"Loss trajectory (last 5):  {[f'{v:.4f}' for v in loss_values[-5:]]}\")\n",
    "    elif loss_values:\n",
    "        print(f\"\\nLoss values: {[f'{v:.4f}' for v in loss_values]}\")\n",
    "    \n",
    "    # Check gradient norms if available\n",
    "    grad_norms = stability.get('grad_norm_values', [])\n",
    "    if grad_norms:\n",
    "        print(f\"\\nGradient norms (last 5): {[f'{v:.2f}' for v in grad_norms[-5:]]}\")\n",
    "        max_grad = max(grad_norms)\n",
    "        if max_grad > 100:\n",
    "            print(f\"Max gradient norm: {max_grad:.2f} - GRADIENT EXPLOSION!\")\n",
    "else:\n",
    "    print(\"Run failed before producing metrics (training crashed early)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Stable vs Unstable with Canary\n",
    "\n",
    "Let's use the canary comparison tool to see how it detects stability regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare unstable run to stable baseline\n",
    "if unstable_paths:\n",
    "    !python -m canary.cli compare {unstable_paths[0]} {stable_path} --threshold-tier smoke\n",
    "else:\n",
    "    print(\"No unstable metrics to compare (run crashed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PPO Stability Monitoring\n",
    "\n",
    "PPO training has additional stability concerns:\n",
    "- **KL divergence**: Policy drifting too far from reference\n",
    "- **Entropy collapse**: Policy becoming too deterministic\n",
    "- **Clip fraction**: Too much clipping = unstable updates\n",
    "\n",
    "Let's run a PPO canary and examine these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PPO smoke test\n",
    "!python -m canary.cli run configs/ppo_smoke.yaml -o ./stability_output/ppo_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine PPO stability metrics\n",
    "ppo_paths = list(Path('./stability_output/ppo_stable').rglob('metrics.json'))\n",
    "\n",
    "if ppo_paths:\n",
    "    with open(ppo_paths[0]) as f:\n",
    "        ppo_metrics = json.load(f)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PPO RUN - STABILITY METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    stability = ppo_metrics['stability']\n",
    "    print(f\"\\nCore Stability:\")\n",
    "    print(f\"  NaN steps:      {stability['nan_steps']}\")\n",
    "    print(f\"  Inf steps:      {stability['inf_steps']}\")\n",
    "    print(f\"  Loss diverged:  {stability['loss_diverged']}\")\n",
    "    print(f\"  Final loss:     {stability['final_loss']}\")\n",
    "    \n",
    "    print(f\"\\nPPO-Specific (tracked in loss_values):\")\n",
    "    loss_values = stability.get('loss_values', [])\n",
    "    if loss_values:\n",
    "        print(f\"  Loss trajectory: {len(loss_values)} values recorded\")\n",
    "        print(f\"  First 3 losses: {[f'{v:.4f}' for v in loss_values[:3]]}\")\n",
    "        print(f\"  Last 3 losses:  {[f'{v:.4f}' for v in loss_values[-3:]]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PPO HEALTH INDICATORS\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nNote: PPO-specific metrics (KL, entropy, clipfrac) are logged\")\n",
    "    print(\"during training and checked for NaN/Inf. Look at training logs\")\n",
    "    print(\"above for 'objective/kl', 'objective/entropy', 'ppo/clipfrac'.\")\n",
    "    \n",
    "    print(\"\\nHealthy PPO indicators:\")\n",
    "    print(\"  - KL divergence: Should stay below target_kl (6.0)\")\n",
    "    print(\"  - Entropy: Should decrease slowly, not collapse\")\n",
    "    print(\"  - Clip fraction: < 0.2 is normal, > 0.3 is concerning\")\n",
    "else:\n",
    "    print(\"PPO run failed to produce metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inject PPO Instability: Extreme KL Coefficient\n",
    "\n",
    "Let's create a PPO config that will cause KL explosion by setting an extreme KL coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unstable PPO config\n",
    "unstable_ppo_config = \"\"\"\n",
    "name: ppo_unstable_kl\n",
    "description: Intentionally unstable PPO - extreme init_kl_coef\n",
    "\n",
    "# Model configuration\n",
    "model_name: EleutherAI/pythia-70m\n",
    "use_peft: true\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "\n",
    "# Training configuration\n",
    "training_type: ppo\n",
    "max_steps: 30\n",
    "batch_size: 2\n",
    "gradient_accumulation_steps: 4\n",
    "learning_rate: 1.0e-4   # Higher LR\n",
    "max_length: 256\n",
    "warmup_steps: 2\n",
    "\n",
    "# PPO-specific - UNSTABLE SETTINGS\n",
    "ppo_epochs: 8         # More epochs per step\n",
    "init_kl_coef: 0.01    # Very low KL penalty - allows policy to drift\n",
    "target_kl: 100.0      # Very high target - won't adapt\n",
    "cliprange: 0.4        # Wider clipping - less stable\n",
    "vf_coef: 0.1\n",
    "max_prompt_length: 64\n",
    "max_new_tokens: 64\n",
    "use_synthetic_reward: true\n",
    "\n",
    "# Dataset configuration\n",
    "dataset_name: Anthropic/hh-rlhf\n",
    "dataset_split: train\n",
    "dataset_size: 128\n",
    "seed: 42\n",
    "\n",
    "# Output configuration\n",
    "output_dir: ./stability_output\n",
    "metrics_warmup_steps: 2\n",
    "\n",
    "profiler:\n",
    "  enabled: false\n",
    "\"\"\"\n",
    "\n",
    "with open('configs/ppo_unstable_kl.yaml', 'w') as f:\n",
    "    f.write(unstable_ppo_config)\n",
    "\n",
    "print(\"Created unstable PPO config:\")\n",
    "print(\"  - init_kl_coef: 0.01 (normal: 0.2) - weak KL penalty\")\n",
    "print(\"  - target_kl: 100.0 (normal: 6.0) - won't adapt\")\n",
    "print(\"  - cliprange: 0.4 (normal: 0.2) - less stable updates\")\n",
    "print(\"  - ppo_epochs: 8 (normal: 4) - more aggressive updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the unstable PPO config\n",
    "!python -m canary.cli run configs/ppo_unstable_kl.yaml -o ./stability_output/ppo_unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PPO runs\n",
    "ppo_unstable_paths = list(Path('./stability_output/ppo_unstable').rglob('metrics.json'))\n",
    "\n",
    "if ppo_unstable_paths and ppo_paths:\n",
    "    with open(ppo_unstable_paths[0]) as f:\n",
    "        ppo_unstable_metrics = json.load(f)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PPO COMPARISON: Stable vs Unstable\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    stable_stab = ppo_metrics['stability']\n",
    "    unstable_stab = ppo_unstable_metrics['stability']\n",
    "    \n",
    "    print(f\"\\n{'Metric':<20} {'Stable':>15} {'Unstable':>15}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"{'NaN steps':<20} {stable_stab['nan_steps']:>15} {unstable_stab['nan_steps']:>15}\")\n",
    "    print(f\"{'Inf steps':<20} {stable_stab['inf_steps']:>15} {unstable_stab['inf_steps']:>15}\")\n",
    "    print(f\"{'Loss diverged':<20} {str(stable_stab['loss_diverged']):>15} {str(unstable_stab['loss_diverged']):>15}\")\n",
    "    \n",
    "    stable_final = stable_stab.get('final_loss')\n",
    "    unstable_final = unstable_stab.get('final_loss')\n",
    "    stable_str = f\"{stable_final:.4f}\" if stable_final else \"N/A\"\n",
    "    unstable_str = f\"{unstable_final:.4f}\" if unstable_final else \"N/A\"\n",
    "    print(f\"{'Final loss':<20} {stable_str:>15} {unstable_str:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Early Warning Patterns\n",
    "\n",
    "The goal of stability monitoring is to predict run failure **before** it happens. Here are patterns to watch for:\n",
    "\n",
    "### Warning Signs (30+ minutes before failure)\n",
    "\n",
    "| Pattern | What it means | Action |\n",
    "|---------|--------------|--------|\n",
    "| Loss increasing for 5+ steps | Training diverging | Reduce LR, check data |\n",
    "| Gradient norm > 10x normal | Gradient explosion starting | Add gradient clipping |\n",
    "| KL spike (PPO) | Policy drifting from reference | Increase KL penalty |\n",
    "| Entropy dropping rapidly | Policy collapsing | Add entropy bonus |\n",
    "| Clip fraction > 0.3 (PPO) | Updates too aggressive | Reduce LR or cliprange |\n",
    "\n",
    "### The \"Death Spiral\" Pattern\n",
    "\n",
    "```\n",
    "Step N:   Loss slightly up      <- Early warning\n",
    "Step N+5: Loss up more, grad norm rising\n",
    "Step N+10: Grad norm spiking    <- Last chance to save\n",
    "Step N+15: NaN detected         <- Too late\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate loss trajectory analysis\n",
    "def analyze_loss_trajectory(loss_values):\n",
    "    \"\"\"Analyze loss trajectory for early warning signs.\"\"\"\n",
    "    if len(loss_values) < 10:\n",
    "        return \"Insufficient data for trajectory analysis\"\n",
    "    \n",
    "    # Split into early and late phases\n",
    "    early = loss_values[:len(loss_values)//3]\n",
    "    late = loss_values[-len(loss_values)//3:]\n",
    "    \n",
    "    import statistics\n",
    "    early_avg = statistics.mean(early)\n",
    "    late_avg = statistics.mean(late)\n",
    "    \n",
    "    # Check for concerning patterns\n",
    "    warnings = []\n",
    "    \n",
    "    if late_avg > early_avg * 1.2:\n",
    "        warnings.append(f\"WARN: Loss increased {(late_avg/early_avg - 1)*100:.1f}% from early to late\")\n",
    "    \n",
    "    if late_avg > early_avg * 1.5:\n",
    "        warnings.append(\"CRITICAL: Loss divergence detected!\")\n",
    "    \n",
    "    # Check for increasing trend in recent steps\n",
    "    recent = loss_values[-5:]\n",
    "    if all(recent[i] < recent[i+1] for i in range(len(recent)-1)):\n",
    "        warnings.append(\"WARN: Loss monotonically increasing in last 5 steps\")\n",
    "    \n",
    "    # Check for high variance (instability)\n",
    "    if len(late) > 1:\n",
    "        late_std = statistics.stdev(late)\n",
    "        if late_std > abs(late_avg) * 0.5:\n",
    "            warnings.append(f\"WARN: High loss variance in late phase (std={late_std:.4f})\")\n",
    "    \n",
    "    if not warnings:\n",
    "        return \"OK: Loss trajectory looks healthy\"\n",
    "    \n",
    "    return \"\\n\".join(warnings)\n",
    "\n",
    "# Analyze our runs\n",
    "print(\"=\"*60)\n",
    "print(\"LOSS TRAJECTORY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n--- Stable DPO ---\")\n",
    "print(analyze_loss_trajectory(stable_metrics['stability']['loss_values']))\n",
    "\n",
    "if unstable_paths:\n",
    "    print(\"\\n--- Unstable DPO (high LR) ---\")\n",
    "    print(analyze_loss_trajectory(unstable_metrics['stability']['loss_values']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using Stability Gates in CI/CD\n",
    "\n",
    "The canary system uses stability checks as hard gates. Here's how they work:\n",
    "\n",
    "```yaml\n",
    "# Stability thresholds (from canary/compare/thresholds.py)\n",
    "nan_steps_allowed: 0      # Any NaN = FAIL\n",
    "inf_steps_allowed: 0      # Any Inf = FAIL\n",
    "```\n",
    "\n",
    "These are **non-negotiable** gates - even one NaN or Inf will fail the canary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatic access to stability comparison\n",
    "from canary.compare.stats import compare_to_baseline, load_metrics\n",
    "from canary.compare.thresholds import SMOKE_THRESHOLDS\n",
    "\n",
    "# Load metrics\n",
    "stable = load_metrics(str(stable_path))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STABILITY THRESHOLDS (Smoke Tier)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nnan_steps_allowed: {SMOKE_THRESHOLDS.nan_steps_allowed}\")\n",
    "print(f\"inf_steps_allowed: {SMOKE_THRESHOLDS.inf_steps_allowed}\")\n",
    "print(f\"max_step_time_increase_pct: {SMOKE_THRESHOLDS.max_step_time_increase_pct}%\")\n",
    "print(f\"max_tps_drop_pct: {SMOKE_THRESHOLDS.max_tps_drop_pct}%\")\n",
    "print(f\"max_mem_increase_mb: {SMOKE_THRESHOLDS.max_mem_increase_mb}MB\")\n",
    "print(f\"max_mem_increase_pct: {SMOKE_THRESHOLDS.max_mem_increase_pct}%\")\n",
    "\n",
    "print(\"\\nNote: Stability checks (NaN/Inf) are HARD gates - zero tolerance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Stability metrics** are tracked automatically during training\n",
    "2. **NaN/Inf detection** only checks stability-relevant keys (loss, gradients, KL, etc.)\n",
    "3. **Loss divergence** is detected by comparing early vs late training phases\n",
    "4. **PPO has additional concerns**: KL divergence, entropy collapse, clip fraction\n",
    "5. **Early warning patterns** can predict failure 30+ minutes before NaN\n",
    "\n",
    "### When Stability Checks Fail:\n",
    "\n",
    "1. **NaN detected**: Check learning rate, gradient clipping, data preprocessing\n",
    "2. **Loss diverging**: Reduce learning rate, check data quality\n",
    "3. **KL explosion (PPO)**: Increase KL penalty, reduce number of PPO epochs\n",
    "4. **Entropy collapse (PPO)**: Add entropy bonus, check reward signal\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- See `04_root_cause_analysis.ipynb` for debugging regression causes\n",
    "- See `05_ppo_canary.ipynb` for detailed PPO canary workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}