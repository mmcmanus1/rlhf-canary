name: ppo_unstable
description: Intentionally unstable PPO settings

model_name: EleutherAI/pythia-70m
use_peft: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05

training_type: ppo
max_steps: 30
batch_size: 2
gradient_accumulation_steps: 4
learning_rate: 5.0e-4   # 5x higher LR!
max_length: 256
warmup_steps: 2

# UNSTABLE PPO settings
ppo_epochs: 8           # More aggressive updates
init_kl_coef: 0.05      # Weak KL penalty
target_kl: 20.0         # Very high target
cliprange: 0.3          # Wider clipping
vf_coef: 0.1
max_prompt_length: 64
max_new_tokens: 64
use_synthetic_reward: true

dataset_name: Anthropic/hh-rlhf
dataset_split: train
dataset_size: 128
seed: 42

output_dir: ./ppo_output
metrics_warmup_steps: 2

profiler:
  enabled: false
